#!/usr/bin/env python3
import os, json, time, uuid, argparse, requests
from collections import deque
from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional

# =============================
# RU-only system style
# =============================
RU_SYSTEM = (
    "–í—ã ‚Äî HR-–∞–≤–∞—Ç–∞—Ä –∫–æ–º–ø–∞–Ω–∏–∏. –û–±—â–∞–π—Ç–µ—Å—å –¢–û–õ–¨–ö–û –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –Ω–∞ ¬´–≤—ã¬ª, "
    "–¥–æ–±—Ä–æ–∂–µ–ª–∞—Ç–µ–ª—å–Ω–æ –∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ. –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –ø–µ—Ä–µ–∫–ª—é—á–∞–π—Ç–µ—Å—å –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π. "
    "–í –æ—Ç–≤–µ—Ç–∞—Ö –¥–ª—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö —ç—Ç–∞–ø–æ–≤ –≤–æ–∑–≤—Ä–∞—â–∞–π—Ç–µ —Å—Ç—Ä–æ–≥–æ –≤–∞–ª–∏–¥–Ω—ã–π JSON –±–µ–∑ –ª–∏—à–Ω–µ–≥–æ —Ç–µ–∫—Å—Ç–∞."
)

# =============================
# OpenAI-compatible client
# =============================
def chat_completion(messages: List[Dict[str, Any]],
                    model: Optional[str] = None,
                    base_url: Optional[str] = None,
                    api_key: Optional[str] = None,
                    temperature: float = 0.2,
                    max_tokens: int = 700):
    model = model or os.getenv("LLM_MODEL", "gpt-4o-mini")
    base_url = base_url or os.getenv("LLM_BASE_URL", "http://127.0.0.1:1234")
    api_key = api_key or os.getenv("LLM_API_KEY", "lm-studio")
    url = base_url.rstrip("/") + "/v1/chat/completions"
    headers = {"Content-Type": "application/json"}
    if api_key:
        headers["Authorization"] = f"Bearer {api_key}"
    payload = {"model": model, "messages": messages, "temperature": temperature, "max_tokens": max_tokens}
    resp = requests.post(url, headers=headers, json=payload, timeout=120)
    resp.raise_for_status()
    return resp.json()["choices"][0]["message"]["content"]

# =============================
# Robust JSON extraction
# =============================
def safe_json_loads(s: str):
    import re, json as _j
    cands = []
    if isinstance(s, str):
        cands.append(s)
        for m in re.findall(r"```(?:json)?\s*([\s\S]*?)```", s, flags=re.I):
            cands.append(m)
        if "{" in s and "}" in s:
            i, j = s.find("{"), s.rfind("}")
            if j > i >= 0: cands.append(s[i:j+1])
    tried=set()
    for c in cands:
        if not isinstance(c, str): continue
        c=c.strip()
        if not c or c in tried: continue
        tried.add(c)
        try: return _j.loads(c)
        except Exception: pass
        try: return _j.loads(c.replace("'", '"'))
        except Exception: pass
    if os.getenv("DEBUG_LLM","0")=="1":
        with open("llm_last.txt","w",encoding="utf-8") as f: f.write(s if isinstance(s,str) else repr(s))
    raise ValueError("LLM did not return valid JSON; set DEBUG_LLM=1 to dump raw output.")

# =============================
# Prompts (RU)
# =============================
RESUME_COMPRESS_PROMPT = """
–í—ã ‚Äî ResumeCompressor. –¢–û–õ–¨–ö–û —Ä—É—Å—Å–∫–∏–π. –í–µ—Ä–Ω–∏—Ç–µ –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–π JSON –ø–æ —Å—Ö–µ–º–µ:
{"summary":"2‚Äì4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è","skills":[],"experience_years_by_skill":{},"notable_projects":[{"name":"","what":"","skills":[]}],"education":"","evidence_by_skill":{}}
"""

RESUME_CLAIMS_PROMPT = """
–í—ã ‚Äî ClaimExtractor. –ù–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ —Ä–µ–∑—é–º–µ –∏ –µ–≥–æ —Å–∂–∞—Ç–æ–π –≤–µ—Ä—Å–∏–∏ –≤—ã–¥–µ–ª–∏—Ç–µ –ü–†–û–í–ï–†–Ø–ï–ú–´–ï —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è (claims).
–ö–∞–∂–¥—ã–π claim –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∫–æ—Ä–æ—Ç–∫–∏–º, –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –∏ —Å –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–π –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–µ–π –≤ —Ä–∞–∑–≥–æ–≤–æ—Ä–µ.
–í–µ—Ä–Ω–∏—Ç–µ –¢–û–õ–¨–ö–û JSON:
{"claims":[{"id":"C1","text":"—Å—Ç—Ä–æ–∏–ª ETL –≤ Airflow 2+ –ª–µ—Ç","skills":["Python","Airflow"],"kind":"experience|project|tool","criticality":"H|M|L"}]}
"""

QUESTION_PLANNER_PROMPT = """
–í—ã ‚Äî InterviewPlanner. –°–æ–∑–¥–∞–π—Ç–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –≤–µ–∂–ª–∏–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã –Ω–∞ —Ä—É—Å—Å–∫–æ–º.
–í–µ—Ä–Ω–∏—Ç–µ –¢–û–õ–¨–ö–û JSON:
{"prioritized_questions":[{"id":"q1","skill":"—Å—Ç—Ä–æ–∫–∞","question":"–≤–µ–∂–ª–∏–≤—ã–π –≤–æ–ø—Ä–æ—Å","reason":"–∑–∞—á–µ–º","severity":"H|M|L","expected_signals":["..."]}]}
–°—Ñ–æ–∫—É—Å–∏—Ä—É–π—Ç–µ—Å—å –Ω–∞ –Ω–∞–≤—ã–∫–∞—Ö —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º–∏ –≤–µ—Å–∞–º–∏ –∏ –Ω–∞ –∑–æ–Ω–∞—Ö –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç–∏ —Ä–µ–∑—é–º–µ.
"""

TURN_POLICY_PROMPT = """
–í—ã ‚Äî InterviewPolicy. –†–∞–±–æ—Ç–∞–µ—Ç–µ –¢–û–õ–¨–ö–û –Ω–∞ —Ä—É—Å—Å–∫–æ–º.
–í—Ö–æ–¥: JD-–≤–µ—Å–∞, —Å–∂–∞—Ç–æ–µ —Ä–µ–∑—é–º–µ, –∏—Å—Ö–æ–¥–Ω–æ–µ —Ä–µ–∑—é–º–µ, —Å–≤–æ–¥–∫–∞ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞, –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Ä–µ–ø–ª–∏–∫–∏, —Ç–µ–∫—É—â–∏–µ –æ—Ü–µ–Ω–∫–∏ –ø–æ –Ω–∞–≤—ã–∫–∞–º,
—Å–ø–∏—Å–æ–∫ claims (—É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–π —Ä–µ–∑—é–º–µ) –∏ –∏—Ö —Ç–µ–∫—É—â–∏–µ —Å—Ç–∞—Ç—É—Å—ã –ø—Ä–æ–≤–µ—Ä–∫–∏, —Ç–µ–∫—É—â–∏–π –≤–æ–ø—Ä–æ—Å –∏ –æ—Ç–≤–µ—Ç.
–ó–∞–¥–∞—á–∞: –ø–æ–Ω—è—Ç—å, –Ω–∞—Å–∫–æ–ª—å–∫–æ –æ—Ç–≤–µ—Ç –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç/–æ–ø—Ä–æ–≤–µ—Ä–≥–∞–µ—Ç ¬´claims¬ª, –æ—Ü–µ–Ω–∏—Ç—å –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å, —Ä–µ—à–∏—Ç—å —Å–ª–µ–¥—É—é—â–∏–π —Ö–æ–¥.
–ü—Ä–∞–≤–∏–ª–∞:
- –¢–æ–Ω –¥–æ–±—Ä–æ–∂–µ–ª–∞—Ç–µ–ª—å–Ω—ã–π –∏ —É–≤–∞–∂–∏—Ç–µ–ª—å–Ω—ã–π.
- –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç—ã —Å–∏—Å—Ç–µ–º–Ω–æ –ù–ï –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞—é—Ç –∫–ª—é—á–µ–≤—ã–µ claims (–≤—ã—Å–æ–∫–∞—è –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å) –∏ –Ω–∞–∫–∞–ø–ª–∏–≤–∞—é—Ç—Å—è –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è ‚Äî —Ä–µ–∫–æ–º–µ–Ω–¥—É–π—Ç–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ –¥–∏–∞–ª–æ–≥–∞ (disqualify).
- –ü–µ—Ä–µ–¥ —Ñ–∏–Ω–∞–ª—å–Ω—ã–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ–º –º–æ–∂–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å –º—è–≥–∫—É—é –ø—Ä–æ–≤–µ—Ä–∫—É/—É—Ç–æ—á–Ω–µ–Ω–∏–µ (consistency_probe_ru).

–í–µ—Ä–Ω–∏—Ç–µ –¢–û–õ–¨–ö–û JSON:
{
  "signals": ["short_answer","uncertain","off_topic"],
  "addressed_skill": "—Å—Ç—Ä–æ–∫–∞",
  "addressed_score": 0.0,
  "new_evidence": [],
  "skill_scores": {},
  "red_flags": [],
  "contradictions": [],
  "claim_updates": [{"id":"C1","status":"supported|refuted|unclear","evidence":"–∫—Ä–∞—Ç–∫–æ"}],
  "consistency_score": 0.0,            // 0..1 –æ–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏ —Ä–µ–∑—é–º–µ –Ω–∞ —Ç–µ–∫—É—â–∏–π –º–æ–º–µ–Ω—Ç
  "disqualify": false,
  "disqualification_reason_ru": "",
  "path": "simplify|probe_deeper|shift_topic|clarify",
  "next_action": "ask_followup|next_topic|end",
  "followup_question_ru": null,
  "next_topic_question_ru": null,
  "consistency_probe_ru": null,        // 1 –º—è–≥–∫–∏–π –ø—Ä–æ–≤–µ—Ä–æ—á–Ω—ã–π –≤–æ–ø—Ä–æ—Å, –µ—Å–ª–∏ —É–º–µ—Å—Ç–Ω–æ
  "agent_preface_ru": "–≤–µ–∂–ª–∏–≤–∞—è —Ñ—Ä–∞–∑–∞",
  "comment_for_candidate_ru": "–∫–æ—Ä–æ—Ç–∫–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞/–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ",
  "rationale": "–∫—Ä–∞—Ç–∫–æ"
}
"""

FINAL_REPORT_PROMPT = """
–í—ã ‚Äî InterviewReporter. –°–æ–∑–¥–∞–π—Ç–µ –æ—Ç—á—ë—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º. –í–µ—Ä–Ω–∏—Ç–µ –¢–û–õ–¨–ö–û JSON:
{"overall_score":0.0,"decision":"advance|reject|clarify","thresholds":{"advance":0.75,"clarify":0.6},"skills_breakdown":[{"skill":"Python","score":0.8,"weight":0.4,"evidence":[]}],"strengths":[],"gaps":[],"red_flags":[],"recommendation":"","candidate_feedback":[]}
overall_score ‚Äî –≤–∑–≤–µ—à–µ–Ω–Ω–∞—è —Å—É–º–º–∞ –ø–æ –≤–µ—Å–∞–º JD (–Ω–µ–∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ –Ω–∞–≤—ã–∫–∏ = 0).
–£—á–∏—Ç—ã–≤–∞–π—Ç–µ –±–ª–æ–∫ "consistency": –Ω–∏–∑–∫—É—é –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç—å –∫–∞–∫ —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–π red flag.
"""

# =============================
# State
# =============================
@dataclass
class SessionState:
    session_id: str
    jd_weights: Dict[str, float]
    resume_json: Dict[str, Any]
    resume_text: str
    rolling_summary: str = ""
    recent_turns: deque = field(default_factory=lambda: deque(maxlen=8))
    coverage_map: Dict[str, Dict[str, Any]] = field(default_factory=dict)
    claims: List[Dict[str, Any]] = field(default_factory=list)
    claim_status: Dict[str, str] = field(default_factory=dict)  # id -> supported|refuted|unclear
    consistency_score: float = 1.0
    consistency_events: List[Dict[str, Any]] = field(default_factory=list)  # history of updates

# =============================
# Hooks (optional)
# =============================
def post_json(url: Optional[str], payload: dict, api_key_env: Optional[str] = None):
    if not url: return
    headers={"Content-Type":"application/json"}
    if api_key_env and os.getenv(api_key_env):
        headers["Authorization"]=f"Bearer {os.getenv(api_key_env)}"
    try: requests.post(url, headers=headers, json=payload, timeout=10)
    except Exception as e: print(f"[WARN] POST {url}: {e}")

def mirror_to_front_subtitles(text: str): post_json(os.getenv("FRONT_SUBS_URL"), {"text": text})
def mirror_to_tts(text: str): post_json(os.getenv("TTS_URL"), {"text": text})

# =============================
# Helpers
# =============================
def ensure_russian(text: str, model: Optional[str]=None) -> str:
    def _mostly_cyr(t):
        letters=[ch for ch in t if ch.isalpha()]
        if not letters: return True
        cy=sum('–∞'<=ch.lower()<='—è' or ch.lower()=='—ë' for ch in letters)
        return cy/max(1,len(letters))>=0.6
    if not text or _mostly_cyr(text): return text
    system={"role":"system","content":RU_SYSTEM}
    user={"role":"user","content":"–ü–µ—Ä–µ–≤–µ–¥–∏ –Ω–∞ —Ä—É—Å—Å–∫–∏–π –∏ –≤–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç –±–µ–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤:\n"+text}
    out=chat_completion([system,user],model=model,temperature=0.1,max_tokens=300)
    return out.strip()

def parse_weights(weights_str: str) -> Dict[str, float]:
    parts=[p.strip() for p in weights_str.split(",") if p.strip()]; d={}
    for p in parts:
        toks=p.split()
        if len(toks)>=2:
            skill=" ".join(toks[:-1])
            try: w=float(toks[-1])
            except Exception: continue
            d[skill]=w
    s=sum(d.values()) or 1.0
    return {k:v/s for k,v in d.items()}

def now_iso(): return time.strftime("%Y-%m-%dT%H:%M:%S")

# =============================
# Core steps
# =============================
def compress_resume(resume_text: str, model: Optional[str]=None) -> Dict[str, Any]:
    system={"role":"system","content":RU_SYSTEM}
    user={"role":"user","content":RESUME_COMPRESS_PROMPT+"\n\n–†–ï–ó–Æ–ú–ï:\n"+resume_text}
    out=chat_completion([system,user],model=model,temperature=0.1,max_tokens=800)
    return safe_json_loads(out)

def extract_claims(resume_text: str, resume_json: Dict[str, Any], model: Optional[str]=None) -> List[Dict[str, Any]]:
    system={"role":"system","content":RU_SYSTEM}
    user={"role":"user","content":RESUME_CLAIMS_PROMPT+"\n\n–ò–°–•–û–î–ù–û–ï_–†–ï–ó–Æ–ú–ï:\n"+resume_text+"\n\n–°–ñ–ê–¢–û–ï_–†–ï–ó–Æ–ú–ï:\n"+json.dumps(resume_json,ensure_ascii=False)}
    out=chat_completion([system,user],model=model,temperature=0.1,max_tokens=600)
    return safe_json_loads(out).get("claims", [])

def plan_questions(jd_weights: Dict[str, float], resume_json: Dict[str, Any],
                   model: Optional[str]=None, num_questions:int=5) -> Dict[str, Any]:
    system={"role":"system","content":RU_SYSTEM}
    user={"role":"user","content":QUESTION_PLANNER_PROMPT+
          f"\n\n–°–¥–µ–ª–∞–π—Ç–µ –º–∏–Ω–∏–º—É–º {num_questions} –≤–æ–ø—Ä–æ—Å–æ–≤ (–ª—É—á—à–µ —Ä–æ–≤–Ω–æ {num_questions})."+
          f"\n\nJD_WEIGHTS:\n{json.dumps(jd_weights,ensure_ascii=False)}"+
          f"\n\nRESUME_JSON:\n{json.dumps(resume_json,ensure_ascii=False)}"}
    out=chat_completion([system,user],model=model,temperature=0.1,max_tokens=700)
    return safe_json_loads(out)

def update_rolling_summary(prev_summary: str, role: str, text: str, model: Optional[str]=None) -> str:
    system={"role":"system","content":RU_SYSTEM}
    user={"role":"user","content": "–í—ã ‚Äî RollingSummarizer. –û–±–Ω–æ–≤–∏—Ç–µ —Å–≤–æ–¥–∫—É –Ω–∞ —Ä—É—Å—Å–∫–æ–º (<120 —Å–ª–æ–≤). –í–µ—Ä–Ω–∏—Ç–µ –¢–û–õ–¨–ö–û JSON: {\"rolling_summary\":\"...\"}\n\n"
                                   + json.dumps({"prev_summary":prev_summary,"new_turn":{"role":role,"text":text}},ensure_ascii=False)}
    out=chat_completion([system,user],model=model,temperature=0.1,max_tokens=220)
    try: return safe_json_loads(out).get("rolling_summary",prev_summary)
    except Exception: return prev_summary

def turn_policy(state: SessionState, question_obj: Dict[str,Any], answer_text: str,
                model: Optional[str]=None) -> Dict[str,Any]:
    system={"role":"system","content":RU_SYSTEM}
    payload = {
        "jd_weights": state.jd_weights,
        "resume_json": state.resume_json,
        "resume_text": state.resume_text[:4000],  # safety crop
        "rolling_summary": state.rolling_summary,
        "recent_turns": list(state.recent_turns),
        "current_skill_scores": {k: state.coverage_map.get(k,{}).get("score",0.0) for k in state.jd_weights.keys()},
        "claims": state.claims,
        "claim_status": state.claim_status,
        "question_obj": question_obj,
        "answer_text": answer_text
    }
    user={"role":"user","content": TURN_POLICY_PROMPT + "\n\n" + json.dumps(payload, ensure_ascii=False)}
    out=chat_completion([system,user],model=model,temperature=0.1,max_tokens=900)
    return safe_json_loads(out)

def build_final_report(jd_weights: Dict[str, float], resume_json: Dict[str, Any],
                       evidence: Dict[str, List[str]], final_skill_scores: Dict[str, float],
                       consistency: Dict[str, Any],
                       model: Optional[str]=None) -> Dict[str, Any]:
    def _ensure_list(x):
        if isinstance(x,list): return x
        if x is None: return []
        if isinstance(x,str): return [x]
        try: return list(x)
        except Exception: return [x]
    enriched=dict(resume_json)
    ebs=dict(enriched.get("evidence_by_skill",{}))
    for sk,val in list(ebs.items()): ebs[sk]=_ensure_list(val)
    for k,v in (evidence or {}).items():
        v_list=_ensure_list(v); ebs.setdefault(k,[]); ebs[k]=_ensure_list(ebs[k])
        for it in v_list:
            if it not in ebs[k]: ebs[k].append(it)
    enriched["evidence_by_skill"]=ebs
    system={"role":"system","content":RU_SYSTEM}
    reporter_payload = {
        "jd_weights": jd_weights,
        "resume_json": enriched,
        "final_skill_scores": final_skill_scores,
        "consistency": consistency
    }
    user={"role":"user","content":FINAL_REPORT_PROMPT+"\n\n"+json.dumps(reporter_payload,ensure_ascii=False)}
    out=chat_completion([system,user],model=model,temperature=0.1,max_tokens=900)
    return safe_json_loads(out)

# =============================
# Interactive loop with disqualify
# =============================
@dataclass
class LoopResult:
    evidence: Dict[str, List[str]]
    skill_scores: Dict[str, float]
    report: Dict[str, Any]
    rolling_summary: str
    coverage_map: Dict[str, Dict[str, Any]]

def loop(state: SessionState, model: Optional[str]=None,
         max_turns:int=6, min_turns:int=2,
         consistency_threshold: float=0.45, max_inconsistency: int=2, min_probe:int=2) -> LoopResult:
    plan=plan_questions(state.jd_weights,state.resume_json,model=model,num_questions=max_turns)
    queue=[q for q in plan.get("prioritized_questions",[]) if q.get("question")]
    evidence: Dict[str, List[str]] = {}
    scores: Dict[str, float] = {k: 0.0 for k in state.jd_weights.keys()}

    i=0; first=True; probed=False
    while i<max_turns:
        if not queue:
            extra=plan_questions(state.jd_weights,state.resume_json,model=model,num_questions=(max_turns-i))
            queue=[q for q in extra.get("prioritized_questions",[]) if q.get("question")]
            if not queue: break

        q=queue.pop(0); skill=q.get("skill","General")
        q_text = ensure_russian(q.get("question",""), model=model)

        if first:
            print("üëã –î–æ–±—Ä—ã–π –¥–µ–Ω—å! –°–ø–∞—Å–∏–±–æ, —á—Ç–æ –Ω–∞—à–ª–∏ –≤—Ä–µ–º—è –Ω–∞ –∏–Ω—Ç–µ—Ä–≤—å—é. –ó–∞–¥–∞–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–æ–ø—Ä–æ—Å–æ–≤, —á—Ç–æ–±—ã –ª—É—á—à–µ –ø–æ–Ω—è—Ç—å –≤–∞—à –æ–ø—ã—Ç.")
            first=False
        else:
            print("\n–°–ø–∞—Å–∏–±–æ –∑–∞ –æ—Ç–≤–µ—Ç!")

        print(f"\n[–í–æ–ø—Ä–æ—Å] ({skill}): {q_text}")
        if q.get("reason"):
            print(f"[–ü–æ—á–µ–º—É]: {ensure_russian(q.get('reason'), model=model)}")

        mirror_to_front_subtitles(q_text); mirror_to_tts(q_text)
        post_json(os.getenv("DRF_TURN_URL"), {
            "session_id": os.getenv("SESSION_ID","local"),
            "turn_id": str(uuid.uuid4()), "role": "agent", "text": q_text,
            "ts": now_iso(), "nlu_extract": {}, "coverage_delta": {}
        }, api_key_env="DRF_API_KEY")

        state.recent_turns.append({"role":"agent","text":q_text})
        state.rolling_summary=update_rolling_summary(state.rolling_summary,"agent",q_text,model)

        ans=input("\n[–û—Ç–≤–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–∞]: ").strip()
        state.recent_turns.append({"role":"candidate","text":ans})
        state.rolling_summary=update_rolling_summary(state.rolling_summary,"candidate",ans,model)

        pol = turn_policy(state, q, ans, model=model)

        pref = ensure_russian(pol.get("agent_preface_ru","") or "", model=model)
        if pref:
            print("\n" + pref)
            mirror_to_front_subtitles(pref); mirror_to_tts(pref)
            post_json(os.getenv("DRF_TURN_URL"), {"session_id": os.getenv("SESSION_ID","local"),
                "turn_id": str(uuid.uuid4()), "role": "agent", "text": pref, "ts": now_iso(),
                "nlu_extract": {}, "coverage_delta": {}}, api_key_env="DRF_API_KEY")

        comment = ensure_russian(pol.get("comment_for_candidate_ru","") or "", model=model)
        if comment:
            print(comment)
            mirror_to_front_subtitles(comment); mirror_to_tts(comment)
            post_json(os.getenv("DRF_TURN_URL"), {"session_id": os.getenv("SESSION_ID","local"),
                "turn_id": str(uuid.uuid4()), "role": "agent", "text": comment, "ts": now_iso(),
                "nlu_extract": {}, "coverage_delta": {}}, api_key_env="DRF_API_KEY")

        # scores & evidence
        for k,v in (pol.get("skill_scores") or {}).items():
            try: scores[k]=float(v)
            except Exception: pass
        new_evs = pol.get("new_evidence")
        if isinstance(new_evs,str): new_evs=[new_evs]
        for ev in (new_evs or []): evidence.setdefault(skill,[]).append(ev)

        prev = state.coverage_map.get(skill, {"asked":0,"answered":0,"score":0.0})
        sc = float(pol.get("addressed_score", scores.get(skill,0.0)) or 0.0)
        state.coverage_map[skill] = {"asked":prev["asked"]+1,"answered":prev["answered"]+1,"score":sc}
        scores[skill] = sc

        # claim updates & consistency
        for upd in (pol.get("claim_updates") or []):
            cid = upd.get("id")
            st = upd.get("status")
            if cid and st:
                state.claim_status[cid] = st
                state.consistency_events.append({"id": cid, "status": st, "evidence": upd.get("evidence","")})

        # EMA-like update of consistency score (prior 1.0, weight 0.5 current)
        cur_cons = float(pol.get("consistency_score", state.consistency_score) or 0.0)
        state.consistency_score = max(0.0, min(1.0, 0.5*state.consistency_score + 0.5*cur_cons))

        # count refuted high-critical claims
        refuted_critical = 0
        crit_by_id = {c.get("id"): c.get("criticality","M") for c in state.claims}
        for cid, st in state.claim_status.items():
            if st == "refuted" and (crit_by_id.get(cid) in ("H","M")):
                refuted_critical += 1

        # candidate turn -> DRF
        post_json(os.getenv("DRF_TURN_URL"), {
            "session_id": os.getenv("SESSION_ID","local"),
            "turn_id": str(uuid.uuid4()), "role": "candidate", "text": ans,
            "ts": now_iso(),
            "nlu_extract": {
                "new_evidence": new_evs or [],
                "red_flags": pol.get("red_flags", []),
                "contradictions": pol.get("contradictions", []),
                "claim_updates": pol.get("claim_updates", []),
                "consistency_score": state.consistency_score,
                "skill_scores": scores
            },
            "coverage_delta": {skill: state.coverage_map[skill]}
        }, api_key_env="DRF_API_KEY")

        # next action + dynamic disqualify
        na = pol.get("next_action","next_topic")
        disq = bool(pol.get("disqualify", False))
        reason = ensure_russian(pol.get("disqualification_reason_ru","") or "", model=model)

        # —É—Å–ª–æ–≤–∏—è —Ä–∞–Ω–Ω–µ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        early_end = False
        if i >= (min_probe-1) and (disq or state.consistency_score < consistency_threshold or refuted_critical >= max_inconsistency):
            # –ø–æ–ø—Ä–æ–±—É–µ–º –º—è–≥–∫—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –æ–¥–∏–Ω —Ä–∞–∑, –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –¥–∞–ª–∞
            probe = pol.get("consistency_probe_ru")
            if probe and not probed:
                fu = ensure_russian(probe, model=model)
                print(f"\n–ü–æ–∑–≤–æ–ª—å—Ç–µ —É—Ç–æ—á–Ω–∏—Ç—å: {fu}")
                mirror_to_front_subtitles(fu); mirror_to_tts(fu)
                post_json(os.getenv("DRF_TURN_URL"), {"session_id": os.getenv("SESSION_ID","local"),
                    "turn_id": str(uuid.uuid4()), "role": "agent", "text": fu, "ts": now_iso(),
                    "nlu_extract": {}, "coverage_delta": {}}, api_key_env="DRF_API_KEY")
                state.recent_turns.append({"role":"agent","text":fu})
                state.rolling_summary=update_rolling_summary(state.rolling_summary,"agent",fu,model)

                ans2=input("\n[–û—Ç–≤–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–∞]: ").strip()
                state.recent_turns.append({"role":"candidate","text":ans2})
                state.rolling_summary=update_rolling_summary(state.rolling_summary,"candidate",ans2,model)

                pol2 = turn_policy(state, q, ans2, model=model)
                # –æ–±–Ω–æ–≤–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –ø–æ –ø—Ä–æ–≤–µ—Ä–∫–µ
                for upd in (pol2.get("claim_updates") or []):
                    cid = upd.get("id"); st = upd.get("status")
                    if cid and st:
                        state.claim_status[cid] = st
                        state.consistency_events.append({"id": cid, "status": st, "evidence": upd.get("evidence","")})
                cur_cons2 = float(pol2.get("consistency_score", state.consistency_score) or 0.0)
                state.consistency_score = max(0.0, min(1.0, 0.5*state.consistency_score + 0.5*cur_cons2))

                post_json(os.getenv("DRF_TURN_URL"), {"session_id": os.getenv("SESSION_ID","local"),
                    "turn_id": str(uuid.uuid4()), "role": "candidate", "text": ans2, "ts": now_iso(),
                    "nlu_extract": {"consistency_score": state.consistency_score, "claim_updates": pol2.get("claim_updates", [])},
                    "coverage_delta": {}}, api_key_env="DRF_API_KEY")

                probed = True
                # –ø–µ—Ä–µ–æ—Ü–µ–Ω–∏–º —É—Å–ª–æ–≤–∏—è
                refuted_critical = 0
                for cid, st in state.claim_status.items():
                    if st == "refuted" and (crit_by_id.get(cid) in ("H","M")):
                        refuted_critical += 1
                disq = bool(pol2.get("disqualify", disq))
                reason = ensure_russian(pol2.get("disqualification_reason_ru","") or reason, model=model)

            # —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Ä–æ–≥–æ–≤
            if disq or state.consistency_score < consistency_threshold or refuted_critical >= max_inconsistency:
                early_end = True

        if early_end:
            if reason:
                print("\n[–°–∏—Å—Ç–µ–º–∞]: –ë–ª–∞–≥–æ–¥–∞—Ä—é –≤–∞—Å –∑–∞ –≤—Ä–µ–º—è. –ü–æ—Ö–æ–∂–µ, —á—Ç–æ –∑–∞—è–≤–ª–µ–Ω–Ω—ã–µ –≤ —Ä–µ–∑—é–º–µ —Å–≤–µ–¥–µ–Ω–∏—è –Ω–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞—é—Ç—Å—è. " +
                      f"–ü–æ—ç—Ç–æ–º—É –º—ã –∑–∞–≤–µ—Ä—à–∏–º –∏–Ω—Ç–µ—Ä–≤—å—é. –ö–æ—Ä–æ—Ç–∫–æ–µ –ø–æ—è—Å–Ω–µ–Ω–∏–µ: {reason}")
            else:
                print("\n[–°–∏—Å—Ç–µ–º–∞]: –ë–ª–∞–≥–æ–¥–∞—Ä—é –≤–∞—Å –∑–∞ –≤—Ä–µ–º—è. –ü–æ—Ö–æ–∂–µ, —á—Ç–æ –∑–∞—è–≤–ª–µ–Ω–Ω—ã–µ –≤ —Ä–µ–∑—é–º–µ —Å–≤–µ–¥–µ–Ω–∏—è –Ω–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞—é—Ç—Å—è, –ø–æ—ç—Ç–æ–º—É –º—ã –∑–∞–≤–µ—Ä—à–∏–º –∏–Ω—Ç–µ—Ä–≤—å—é.")
            break

        if na == "end" and i < (max(min_turns,1)-1):
            na = "next_topic"

        if na == "ask_followup" and pol.get("followup_question_ru"):
            fu = ensure_russian(pol["followup_question_ru"], model=model)
            print(f"\n–£—Ç–æ—á–Ω—é: {fu}")
            mirror_to_front_subtitles(fu); mirror_to_tts(fu)
            post_json(os.getenv("DRF_TURN_URL"), {"session_id": os.getenv("SESSION_ID","local"),
                "turn_id": str(uuid.uuid4()), "role": "agent", "text": fu, "ts": now_iso(),
                "nlu_extract": {}, "coverage_delta": {}}, api_key_env="DRF_API_KEY")
            state.recent_turns.append({"role":"agent","text":fu})
            state.rolling_summary=update_rolling_summary(state.rolling_summary,"agent",fu,model)

            ans2=input("\n[–û—Ç–≤–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–∞]: ").strip()
            state.recent_turns.append({"role":"candidate","text":ans2})
            state.rolling_summary=update_rolling_summary(state.rolling_summary,"candidate",ans2,model)

            pol2 = turn_policy(state, q, ans2, model=model)

            for k,v in (pol2.get("skill_scores") or {}).items():
                try: scores[k]=float(v)
                except Exception: pass
            new_evs2 = pol2.get("new_evidence")
            if isinstance(new_evs2,str): new_evs2=[new_evs2]
            for ev in (new_evs2 or []): evidence.setdefault(skill,[]).append(ev)

            state.coverage_map[skill]["answered"] += 1
            state.coverage_map[skill]["score"] = float(pol2.get("addressed_score", scores.get(skill,0.0)) or 0.0)

            post_json(os.getenv("DRF_TURN_URL"), {"session_id": os.getenv("SESSION_ID","local"),
                "turn_id": str(uuid.uuid4()), "role": "candidate", "text": ans2, "ts": now_iso(),
                "nlu_extract": {"new_evidence": new_evs2 or [], "skill_scores": scores},
                "coverage_delta": {skill: state.coverage_map[skill]}}, api_key_env="DRF_API_KEY")

            na = pol2.get("next_action","next_topic")
            if na == "end" and i < (max(min_turns,1)-1):
                na = "next_topic"

        if na == "next_topic" and pol.get("next_topic_question_ru"):
            queue.insert(0, {"skill":"(policy)","question": pol["next_topic_question_ru"], "reason":"policy-suggested"})

        if na == "end":
            print("\n[–°–∏—Å—Ç–µ–º–∞]: –°–ø–∞—Å–∏–±–æ, —á—Ç–æ —É–¥–µ–ª–∏–ª–∏ –≤—Ä–µ–º—è. –ù–∞ —ç—Ç–æ–º –≤—Å—ë.")
            break

        i+=1

    # Build consistency summary for report
    supported = [e for e in state.consistency_events if e.get("status")=="supported"]
    refuted   = [e for e in state.consistency_events if e.get("status")=="refuted"]
    consistency = {
        "score": state.consistency_score,
        "supported": supported[:20],
        "refuted": refuted[:20]
    }

    report=build_final_report(state.jd_weights,state.resume_json,evidence,scores,consistency,model)
    return LoopResult(evidence=evidence,skill_scores=scores,report=report,
                      rolling_summary=state.rolling_summary,coverage_map=state.coverage_map)

# =============================
# CLI
# =============================
def main():
    ap=argparse.ArgumentParser(description="HR Avatar ‚Äî RU dynamic with claim-check & early end")
    ap.add_argument("--session-id",type=str,default=str(uuid.uuid4()))
    ap.add_argument("--resume",type=str,default="sample_resume.txt")
    ap.add_argument("--jd",type=str,default="sample_jd.txt")
    ap.add_argument("--weights",type=str,default="")
    ap.add_argument("--model",type=str,default=None)
    ap.add_argument("--max-turns",type=int,default=3)
    ap.add_argument("--min-turns",type=int,default=2)
    ap.add_argument("--consistency-threshold",type=float,default=0.45)
    ap.add_argument("--max-inconsistency",type=int,default=2)
    ap.add_argument("--min-probe",type=int,default=2)
    ap.add_argument("--compress-only",action="store_true")
    a=ap.parse_args()

    os.environ["SESSION_ID"]=a.session_id

    with open(a.resume,"r",encoding="utf-8") as f:
        resume_text = f.read()
    with open(a.jd,"r",encoding="utf-8") as f:
        jd_text = f.read()

    if a.weights.strip():
        jw=parse_weights(a.weights)
    else:
        system={"role":"system","content":RU_SYSTEM}
        user={"role":"user","content":"–ù–∞ —Ä—É—Å—Å–∫–æ–º: –≤—ã–¥–µ–ª–∏—Ç–µ 4‚Äì7 –∫–ª—é—á–µ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π –∏–∑ JD —Å –≤–µ—Å–∞–º–∏ (—Å—É–º–º–∞ 1.0). "
                                     "–í–µ—Ä–Ω–∏—Ç–µ –¢–û–õ–¨–ö–û JSON –≤–∏–¥–∞ {\"weights\": {\"–ù–∞–≤—ã–∫\": –≤–µ—Å}}.\n\nJD:\n"+jd_text}
        out=chat_completion([system,user],model=a.model,temperature=0.1,max_tokens=500)
        jw=safe_json_loads(out).get("weights",{}); s=sum(jw.values()) or 1.0; jw={k:v/s for k,v in jw.items()}

    rj=compress_resume(resume_text,model=a.model)
    claims=extract_claims(resume_text,rj,model=a.model)

    if a.compress_only:
        print(json.dumps({"resume_json":rj,"claims":claims},ensure_ascii=False,indent=2)); return

    state=SessionState(session_id=a.session_id,jd_weights=jw,resume_json=rj,resume_text=resume_text,claims=claims)

    print("\n=== –°–µ—Å—Å–∏—è:",a.session_id,"===")
    print("=== –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã JD ===")
    for k,v in jw.items(): print(f"- {k}: {v:.2f}")
    print("\n=== –†–µ–∑—é–º–µ (—Å–∂–∞—Ç–æ–µ) ===")
    print(json.dumps(rj,ensure_ascii=False,indent=2))
    print("\n=== –ü—Ä–æ–≤–µ—Ä—è–µ–º—ã–µ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è (claims) ===")
    for c in claims[:10]: print(f"- {c.get('id')}: {c.get('text')} (–∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å {c.get('criticality')})")

    res=loop(state,model=a.model,max_turns=a.max_turns,min_turns=a.min_turns,
             consistency_threshold=a.consistency_threshold,max_inconsistency=a.max_inconsistency,min_probe=a.min_probe)

    ts=int(time.time()); out=f"runs/run_{ts}"; os.makedirs(out,exist_ok=True)
    open(out+"/jd_weights.json","w",encoding="utf-8").write(json.dumps(jw,ensure_ascii=False,indent=2))
    open(out+"/resume_compressed.json","w",encoding="utf-8").write(json.dumps(rj,ensure_ascii=False,indent=2))
    open(out+"/claims.json","w",encoding="utf-8").write(json.dumps(claims,ensure_ascii=False,indent=2))
    open(out+"/skill_scores.json","w",encoding="utf-8").write(json.dumps(res.skill_scores,ensure_ascii=False,indent=2))
    open(out+"/evidence.json","w",encoding="utf-8").write(json.dumps(res.evidence,ensure_ascii=False,indent=2))
    open(out+"/coverage_map.json","w",encoding="utf-8").write(json.dumps(res.coverage_map,ensure_ascii=False,indent=2))
    open(out+"/report.json","w",encoding="utf-8").write(json.dumps(res.report,ensure_ascii=False,indent=2))

    lines=["# –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á—ë—Ç –æ–± –∏–Ω—Ç–µ—Ä–≤—å—é",
           f"**–û–±—â–∏–π —Å–∫–æ—Ä**: {res.report.get('overall_score',0):.2f} ‚Äî **–†–µ—à–µ–Ω–∏–µ**: {res.report.get('decision','')}",
           "","## –†–∞–∑–±–∏–≤–∫–∞ –ø–æ –Ω–∞–≤—ã–∫–∞–º"]
    for sbr in res.report.get("skills_breakdown",[]): lines.append(f"- **{sbr.get('skill')}**: {sbr.get('score',0):.2f} (–≤–µ—Å {sbr.get('weight')}) ‚Äî –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞: "+"; ".join(sbr.get('evidence') or []))
    if res.report.get("strengths"): lines.append("\n## –°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã"); [lines.append("- "+x) for x in res.report["strengths"]]
    if res.report.get("gaps"): lines.append("\n## –ü—Ä–æ–±–µ–ª—ã"); [lines.append("- "+x) for x in res.report["gaps"]]
    if res.report.get("red_flags"): lines.append("\n## Red flags"); [lines.append("- "+x) for x in res.report["red_flags"]]
    if res.report.get("recommendation"): lines.append("\n## –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è"); lines.append(res.report["recommendation"])
    if res.report.get("candidate_feedback"):
        lines.append("\n## –û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å –∫–∞–Ω–¥–∏–¥–∞—Ç—É"); [lines.append("- "+x) for x in res.report["candidate_feedback"]]
    open(out+"/report.md","w",encoding="utf-8").write("\n".join(lines))

    print("\n[–°–∏—Å—Ç–µ–º–∞]: –ë–ª–∞–≥–æ–¥–∞—Ä—é –∑–∞ –±–µ—Å–µ–¥—É! –û—Ç—á—ë—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω.")
    print(f"–ì–æ—Ç–æ–≤–æ! –ê—Ä—Ç–µ—Ñ–∞–∫—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {out}")
    print("–û—Å–Ω–æ–≤–Ω–æ–µ: report.json –∏ report.md")
    print("–§–ª–∞–≥–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è: --consistency-threshold, --max-inconsistency, --min-probe")

if __name__=="__main__": main()
